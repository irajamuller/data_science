{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTLyW/pSMtUP2ik8THDpWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irajamuller/data_science/blob/main/Prepara%C3%A7%C3%A3o_de_Dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy\n",
        "\n",
        "O `ndarray` é a estrutura de dados básica da biblioteca Numpy. Qualquer um dos métodos analíticos implementados pelo NumPy irá requerer que os dados estejam armazenados nesta estrutura. Por se tratar de uma estrutura voltada para alto desempenho, o ndarray é implementado como um nódulo de baixo nível escrito na linguagem C utilizando a API para interface com a linguagem Python. Este método de implmeentação é comumente utilizado por módulos que requerem operações de alto desempenho, as quais não são suportadas pelos métodos ou estruturas nativas da linguagem Python.\n",
        "\n",
        "Em baixo nível, o ndarray é uma estrutura de dados alocada de forma contígua em memória, armazenando elementos de forma compacta e homogênea em memória. Diferentemente das estruturas básicas do Python, um ndarray armazena valores de um único tipo de dados, o qual é definido no momento em que a estrutura é instanciada. Há suporte para a maioria dos tipos inteiros e de ponto flutuante que estão disponíveis em linguagens de programação com tipagem forte (tal como o C). A informação do tipo de dados encontra-se armazenada em uma estrutura de cabeçalho, a qual também irá conter outros metadados da estrutura, tal como duas dimensões e tamanhos. Estas informações são utilizadas para controlar operações de leitura e escrita de dados na estrutura de forma eficiente por cálculos de deslocamento. A figura abaixo apresenta um diagrama que sumariza a estrutura de baixo nível do ndarray.\n",
        "\n",
        "![Estrutura do ndarray](https://raw.githubusercontent.com/irajamuller/data_science/main/figs/ndarray_structure.jpg)\n",
        "\n",
        "Por se tratar de uma estrutura simples e eficiente para manipulação de dados numéricos vetoriais, o ndarray é utilizado internamente por uma ampla gama de outras bibliotecas do Python que também tem o requisito de alto desempenho. Alguns exemplos incluem Pytorch e Tensorflow (duas bibliotecas amplamente utilizadas para trabalho com redes neurais profundas), OpenCV (biblioteca para trabalho com visão computacional), e a própria Pandas.\n",
        "\n",
        "Neste notebook iremos aprender algumas das funções básicas disponíveis para a criação e manipulação de ndarrays. Antes de qualquer coisa, precisamos instalar a biblioteca NumPy em nosso ambiente Python e importar o NumPy para nosso notebook."
      ],
      "metadata": {
        "id": "3YSjVf-dlsl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip show numpy\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ttiEwFpdx3io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o a biblioteca NumPy importada, podemos utilizar os métodos disponíveis para a criação de ndarrays com diferentes características. Uma possibilidade é a criação de um ndarray com todos os valores inicializados com zero. Para isso, podemos utilizar o método `zeros`. O primeiro parâmetro para este método são as dimensões do ndarray, que no caso de duas dimensões será uma tupla `(linhas, colunas)`. Também utilizaremos o parâmetro `dtype` para especificar o tipo de dado que será armazenado, que no exemplo será um inteiro de 32 bits."
      ],
      "metadata": {
        "id": "8qYYEuqQyTON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndarray = np.zeros((3, 4), dtype=np.int32) # Cria um ndarray com dimensões 3 por 4\n",
        "print(ndarray)"
      ],
      "metadata": {
        "id": "GKpoNrsfybzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste caso, para alterar valores pontuais do ndarray, podemos utilizar indexação de arrays utilizando colchetes, como no exemplo abaixo. Repare que, assim como em outras linguagens de programação, a indexação de linhas e colunas inicia em $0$ e se estende até $n-1$ (onde $n$ é o limite da dimensão que está sendo acessada)."
      ],
      "metadata": {
        "id": "FEWatg7gymjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndarray[1, 2] = 5 # Altera o valor do item na posição [2, 3] para 5\n",
        "print(ndarray)"
      ],
      "metadata": {
        "id": "V7D4SNm3ypQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outro método comumente utilizado para criar um ndarray é a partir de uma outra estrutura do Python, tal como uma lista com valores inteiros. Também podemos utilizar o encadeamento para criar um ndarray utilizando as listas tradicionais do Python, como realizado no exemplo abaixo, através do método `array`. Repare que este método também permite especificar o tipo de dado que será utilizado pelo ndarray."
      ],
      "metadata": {
        "id": "brZ8gA3Bywdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista_python = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12] ]\n",
        "ndarray = np.array(lista_python, dtype=np.float32) # Cria um ndarray utilizando os dados contidos em uma lista do Python\n",
        "print(ndarray)"
      ],
      "metadata": {
        "id": "30wWa5TUy1XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assim como no caso do Pandas, também podemos realizar a carga de dados para um ndarray a partir de um arquivo de texto no formato CSV. O exemplo abaixo utiliza o método `loadtxt` para ler um arquivo CSV, especificando o separador de cada coluna como uma vírgula. O método também permite especificar qual o tipo de dado que será utilizado para a conversão do array.\n",
        "\n",
        "Observe que o ndarray é uma estrutura menos flexível que o Dataframe do Pandas. Enquanto o Dataframe permite converter cada coluna para um tipo de dados distinto, no ndarray espera que todos os valores pertençam ao mesmo tipo de dados."
      ],
      "metadata": {
        "id": "SVRV32pwy8nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temps = np.loadtxt('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/temperaturas_outono.csv'\n",
        ", delimiter=',', dtype=np.float32) # Carrega os dados de um arquivo CSV para um ndarray\n",
        "print(temps)"
      ],
      "metadata": {
        "id": "bUCNukgnzBsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A biblioteca NumPy também permite salvar e carregar os dados de um ndarray de um arquivo binário. Este formato usualmente é referido com a extensão NPY e se trata de um formato binário específico para armazenar informações de um ndarray do NumPy. Este formato é suportado pelo próprio NumPy e por algumas bibliotecas do Python, como o Pandas."
      ],
      "metadata": {
        "id": "G01IBut30Rng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('temperaturas.npy', temps) # Salvar os dados contidos no ndarray em um arquivo binário"
      ],
      "metadata": {
        "id": "xA1Y3Rae0XAD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carregado = np.load('temperaturas.npy') # Carrega os dados contidos para um ndarray. O arquivo deve obedecer o formato binário esperado pelo NumPy\n",
        "print(carregado)"
      ],
      "metadata": {
        "id": "hUOGqiNX0ugU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O NumPy oferece alguns comandos básicos para analisar as propriedades básicas de um ndarray, tais como o tamanho, dimensões, e tipo dos dados. As células abaixo contém exemplos do uso desses comandos utilizando o ndarray que carregamos no último exemplo."
      ],
      "metadata": {
        "id": "N9IBtx5h011J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado.size) # propriedade contendo o número de itens armazenados no ndarray"
      ],
      "metadata": {
        "id": "vYFTe-c804Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado.dtype) # propriedade contendo o tipo de dado armazenado em cada um dos itens do ndarray"
      ],
      "metadata": {
        "id": "mS22p5u105rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado.ndim) # propriedade contendo o número de dimensões contidas no ndarray"
      ],
      "metadata": {
        "id": "bWoe__tt09f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado.shape) # propriedade contendo uma tupla que especifica o tamanho de cada dimensão do ndarray"
      ],
      "metadata": {
        "id": "7KqLGEHw1AqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um exemplo anterior já mostrou que podemos acessar elementos individuais de um ndarray utilizando o operador de indexação do Python (especificando a posição numérica entre colchetes). Podemos utilizar os operadores de indexação do Python para acessar diferentes porções do ndarray. As células abaixo apresentam algusn exemplos de operações de indexação."
      ],
      "metadata": {
        "id": "p7gk9F6m2A3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado[0]) # acessa uma linha completa do array utilizando através da indexação de uma dimensão"
      ],
      "metadata": {
        "id": "IotPX_NV2E28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado[0, :12]) # Acessa os 12 primeiros valores contidos na primeira linha"
      ],
      "metadata": {
        "id": "Au1ig_FN2IXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado[:, :12]) # Acessa os 12 primeiros valores contidos em cada uma das linhas"
      ],
      "metadata": {
        "id": "ijGAxOVn2K79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado[:, 0]) # Cria um ndarray com o primeiro valor de cada uma das linhas"
      ],
      "metadata": {
        "id": "OXPkMZN72SYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um ndarray também pode ser manipulado através de funções de divisão e agregação. Isso permite que, por exemplo, um ndarray seja dividido em um número especificado de partes iguais. As células abaixo apresentam exemplos dos métodos de divisão e concatenação."
      ],
      "metadata": {
        "id": "1rVWHJCN2ike"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "por_dia = np.split(carregado, 7) # divide o ndarray em sete partes iguais na dimensão de mais alto nível\n",
        "for dia in por_dia:\n",
        "    print(dia) # Imprime cada um das divisões criadas pelo comando split."
      ],
      "metadata": {
        "id": "KA8qWncq2mFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatenado = np.concatenate(por_dia)\n",
        "print(concatenado)"
      ],
      "metadata": {
        "id": "YXgTX9ng24uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pandas\n",
        "\n",
        "O dataframe é a principal estrutura de dados disponibilizada pela biblioteca Pandas para o processamento e análise de dados. Todos os métodos disponíveis na bibloteca utilizam o Dataframe como estrutura básica para execução. O dataframe do pandas pode ser comparado com uma planilha de aplicativos como o Microsoft Excel, onde os dados são organizados de forma tabular. Cada linha da tabela representa um registro, identificado unicamente por um valor inteiro, e cada coluna representa um dos campos disponíveis no registro, identificada por uma string.\n",
        "\n",
        "Cada coluna de um dataframe é representada como um objeto do tipo Series do Pandas. Em suma, uma Series é um array indexado por valores inteiros onde todos os elementos pertencem a um mesmo tipo. Cabe ressaltar que tanto o Dataframe quanto a Series são tipos de dados implementados de forma otimizada utilizanod extensões em linguagem de baixo nível de forma a apresentarem alto desempenho ao tratar grandes volumes de dados. A figura abaixo apresenta uma ilustração de como um Dataframe do Pandas é organizado.\n",
        "\n",
        "![Estrutura de um Dataframe do Pandas](https://raw.githubusercontent.com/irajamuller/data_science/main/figs/pandas_structure.jpg)\n",
        "\n",
        "Para utilizarmos um Dataframe, primeiramente precisamos importar a biblioteca Pandas no nosso código."
      ],
      "metadata": {
        "id": "HDu_Nn243iyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n9f0i4Ey8uAJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No exemplo abaixo, iremos criar um novo Dataframe utilizando os dados contidos em um dicionário do Python. Repare na forma como o diconário está organizado e como ele será estruturado na forma de um Dataframe."
      ],
      "metadata": {
        "id": "M-3kGTTR8yPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Nome': ['Ana', 'João', 'Maria', 'Carlos', 'Paula'],\n",
        "    'Idade': [23, 34, 45, 36, 27],\n",
        "    'Cidade': ['SP', 'RJ', 'MG', 'RS', 'SP'],\n",
        "    'Glicose': [85, 140, 95, 200, 105]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df # Jupyter Notebook irá formatar o Dataframe como uma planilha."
      ],
      "metadata": {
        "id": "-vs-F0ma8x0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o Dataframe criado, podemos realizar diferentes atividades de seleção e manipulação dos dados nele contidos."
      ],
      "metadata": {
        "id": "T4IOkOvP9Get"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() # imprime uma série de informações sobre a estrutura do Dataframe."
      ],
      "metadata": {
        "id": "w0XwaU3L-r6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nomes = df['Idade'] # seleciona a Series contendo apenas os dados da coluna \"Idade\"\n",
        "nomes"
      ],
      "metadata": {
        "id": "J3AWmhab9Hbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registros = df[ df['Glicose'] > 100 ] # Selecionar registros aplicando um filtro nos valores de uma coluna\n",
        "registros # Jupyter Notebook irá formatar o Dataframe como uma planilha."
      ],
      "metadata": {
        "id": "HSnh0_g29c4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtro = (df['Glicose'] > 100) & (df['Idade'] < 35) # Vamos definir um filtro com várias condições\n",
        "registros = df[ filtro ] # Vamos selecionar os registros utilizando o filtro\n",
        "registros # Jupyter Notebook irá formatar o Dataframe como uma planilha."
      ],
      "metadata": {
        "id": "XAm43Co79ies"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registro = df.iloc[2] # seleciona um registro em particular (uma das linhas) do Dataframe\n",
        "registro"
      ],
      "metadata": {
        "id": "lhVRlzlU9wBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registro = registros.loc[4] # seleciona um registro em particular (uma das linhas) do Dataframe usando o label\n",
        "registro"
      ],
      "metadata": {
        "id": "wHBqePqM92hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = df.sample() # Seleciona um registro aleatório (uma amostra ou \"sample\") do Dataframe.\n",
        "sample # Jupyter Notebook irá formatar a amostra como uma planilha."
      ],
      "metadata": {
        "id": "xs7QEBjx-kB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_dataframe = df.sort_values('Idade') # Ordena os valores do Dataframe pela coluna passada como parâmetro.\n",
        "sorted_dataframe # Jupyter Notebook irá formatar a amostra como uma planilha."
      ],
      "metadata": {
        "id": "MTrerURd-1Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para os próximos exemplos, precisaremos de um conjunto de dados com maior tamanho. Temos alguns conjuntos de dados de exemplo disponíveis na biblioteca Seaborn (biblioteca de visualização baseada na matplotlib), a qual também é ampalmente utilizada para tarefas de aprendizado de máquina e iremos estudar ao longo da disciplina. A célula abaixo irá carregar a biblioteca Seaborn e, em seguida, carregar um conjunto de dados com dados de gorjetas em restaurantes dos Estados Unidos."
      ],
      "metadata": {
        "id": "Bg6GwRnS_L7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "df = sns.load_dataset('tips')"
      ],
      "metadata": {
        "id": "fpKHnpjc_HcS"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As próximas células irão apresentar mais algumas funções básicas dos Dataframes."
      ],
      "metadata": {
        "id": "9RsxY-1j_uCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10) # Imprime os primeiros registros contidos no Dataframe."
      ],
      "metadata": {
        "collapsed": true,
        "id": "1EfjMhRd_ram"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(10) # Imprime os últimos registros contidos no Dataframe."
      ],
      "metadata": {
        "id": "TXX_CQKkAOou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe() # Apresenta uma análise das tendências centrais dos atributos numéricos contidos no Dataframe."
      ],
      "metadata": {
        "id": "9e5HfoMnASbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também podemos realizar a seleção de subconjuntos de dados de um Dataframe através de operadores de indexação. As células abaixo apresentam exemplos onde selecionamos um subconjunto de registros com todas as colunas e, após, a seleção de um subconjunto de registros de uma coluna específica."
      ],
      "metadata": {
        "id": "zaKTFiEPAhZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[10:19]"
      ],
      "metadata": {
        "id": "kWalBweqAfiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[10:19, 'tip']"
      ],
      "metadata": {
        "id": "arsE677fAqQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pandas - Carregamento\n",
        "Além de utilizar dicionários para criar Dataframes do Pandas, também podemos realizar a carga de dados diretamente de diferentes tipos de fontes de dados. O Pandas possui suporte nativo à leitura de vários formatos estruturados de arquivo, incluindo CSV e planilhas geradas por aplicativos como o Microsoft Excel. Utilizando as funcionalidades do Pandas podemos realizar tanto a leitura quanto a exportação de resultados diretamente para esses formatos.\n",
        "\n",
        "Além disso, o Pandas também possui integração com a biblioteca SQLAlchemy do Python, que permite a interação com diferentes sistemas de gerenciamento de bancos de dados relacionais. Através desta integração podemos realizar a leitura de conjuntos de dados diretamente de tabelas de um banco de dados ou através de manipulações utilizando a linguagem SQL.\n",
        "\n",
        "Este notebook apresenta os métodos que podemos utilizar para adquirir dados de fontes estruturadas no formato CSV (Dados de texto separados por vírgulas), XLSX (planilhas do Excel) e JSON (JavaScript Object Notation). Ele também apresenta como adquirir dados de bancos de dados relacionais utilizando a integração com o SQLAlchemy.\n",
        "\n",
        "Nosso primeiro passo será carregar a biblioteca Pandas para utilizarmos o Dataframe e os métodos de carga de dados."
      ],
      "metadata": {
        "id": "xcLwu39pFQZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pandas - CSV"
      ],
      "metadata": {
        "id": "T23n0miCHYj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/glicose.csv') # Realiza a leitura de um arquivo CSV\n",
        "#df = pd.read_csv('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/glicose.csv', delimiter=',') # Especifica que o caractere delimitador é uma vírgula\n",
        "df.info()"
      ],
      "metadata": {
        "id": "LTPHMWQQFn3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O conjunto de dados que carregamos possui uma coluna \"Estado\" onde cada entrada é classificada pela UF do paciente. Repare que o comando `info` nos mostra que este atributo é do tipo `object`, o padrão para dados de string. Além de dados numéricos e de string, uma coluna também pode ser do tipo **categórico**. Este tipo de dado é muito útil para armazenar atributos que classificam uma entrada de acordo com um determinado conjunto limitado de categorias, tal como a UF de residência ou o tipo sanguíneo.\n",
        "\n",
        "A conversão de uma coluna para um tipo categórico precisa ser realizada de forma explícita através do método `astype`. Este método pode ser executado após o Dataset ter sido carregado de um arquivo."
      ],
      "metadata": {
        "id": "q3sSBbdDGJzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Estado'] = df['Estado'].astype(\"category\") # Converte a coluna \"Estado\" para um tipo categórico\n",
        "df.info()"
      ],
      "metadata": {
        "id": "yVttLSS0GSsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "zeAWhFqTGZ2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também podemos salvar um conjunto de dados em um arquivo CSV através do método `to_csv`. As células abaixo apresentam um exemplo deste método. Primeiro, iremos criar um dataframe com um subconjunto de entradas do nosso dataset original. Então, iremos salvá-lo como um novo arquivo CSV."
      ],
      "metadata": {
        "id": "k3TaHbLYGiOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glicose_rs = df[ df[\"Estado\"] == \"RS\" ]\n",
        "glicose_rs"
      ],
      "metadata": {
        "id": "Y3zmu2iIGhvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glicose_rs.to_csv('glicose_rs.csv', index=False)"
      ],
      "metadata": {
        "id": "DemFylXDGzf7"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pandas - XLSX\n",
        "Podemos realizar a leitura de uma planilha do Excel através do método `read_excel`. Assim como no caso anterior, este comando presumo que a primeira linha da planilha irá conter os nomes dos atributos, os quais serão utilizados para nomear os respectivos atributos no Dataframe. O método também presume que a primeira planilha do arquivo deverá ser lida, mas podemos alterar este comportamento através dos parâmetros do comando.\n",
        "\n",
        "Nota: para que o Pandas consiga ler arquivos do Excel, a biblioteca `openpyxl` precisa ser instalada no ambiente do Python."
      ],
      "metadata": {
        "id": "uCBsXZbIHpMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/glicose.xlsx') # Realiza a leitura de uma planilha do Excel.\n",
        "#df = pd.read_excel('glicose.xlsx', sheet_name='Sheet1') # Especifica o nome da planilha que deve ser lida do arquivo.\n",
        "df.info()"
      ],
      "metadata": {
        "id": "3hOB2UxgIAe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também podemos exportar um Dataframe para um arquivo um arquivo de planilha utilizando o método `to_excel`. É interessante observar que este mesmo método também permite salvar arquivos ODS, que é formato aberto de planilha utilizado pelo LibreOffice. Para isso, utilizamos os parâmetros do método `to_excel` para especificar qual formato queremos utilizar.\n",
        "\n",
        "Nota: para habilitar o suporte ao formato ODS, também precisamos instalar a biblioteca `odfpy` através no ambiente do Python.\n",
        "\n",
        "No exemplo a seguir, iremos criar um dataframe com um subconjunto de dados e então iremos salvá-lo no formato ODS."
      ],
      "metadata": {
        "id": "9resG12iIQt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glicose_sp = df[ df[\"Estado\"] == \"SP\" ]\n",
        "glicose_sp"
      ],
      "metadata": {
        "id": "JKIPrXfvIXHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install odfpy --quiet # Instalação da Engine\n",
        "\n",
        "glicose_sp.to_excel('glicose_sp.ods', engine='odf', index=False)"
      ],
      "metadata": {
        "id": "P0jF421oIad8"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pandas - SGBDR\n",
        "Outro método de aquisição de dados que é bastante popular é através de sistemas de bancos de dados relacionais. O Pandas possui integração com diferentes bibliotecas para acesso a bancos de dados, mas o SQLAlchemy é uma das mais flexíveis. Por si só, o SQLAlchemy possui um conjunto de ferramentas para trabalho com bancos de dados relacionais, como por exemplo um modelo para modelagem objeto-relacionamento.\n",
        "\n",
        "Para utilizar estas funcionalidades com o Pandas, precisamos importar a biblioteca `sqlalchemy` no nosso código. Para uso das funcionalidades mais básicas, podemos importar apenas o método `create_engine`. A constar, precisamos instalar a biblioteca `sqlalchemy` no nosso ambiente Python para poder utilizá-la."
      ],
      "metadata": {
        "id": "eooQ3FSIJX5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install psycopg2-binary sqlalchemy --quiet # Biblioteca de conexão PostgreSQL e a Engine para o Python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NDRMhsIKCcf",
        "outputId": "6fb2cf8f-bf9d-49f0-880f-b4390088db15"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos próximos exemplos, iremos utilizar um conjunto de dados armazenado em um arquivo de banco de dados relacional do PostgreSQL. Este banco de dados possui uma única tabela denominada `glicose`, a qual possui a mesma estrutura do arquivo CSV que utilizamos em exemplos anteriores. Para importar a estrutura completa da tabela do banco de dados, podemos seguir o exemplo abaixo."
      ],
      "metadata": {
        "id": "t3OkchY5JocF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "engine = create_engine(f'postgresql+psycopg2://dell:dell@localhost:5432/dell') # Cria uma conexão com o banco de dados utilizando o SQLAlchemy\n",
        "df = pd.read_sql(\"glicose\", engine) # Realiza a leitura dos dados da tabela para um Dataframe\n",
        "engine.dispose() # Encerra a conexão com o banco de dados\n",
        "\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "eZL5lciTIh8O",
        "outputId": "94573aa2-f3f1-43e4-c68a-c8ad183379b2"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OperationalError",
          "evalue": "(psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (::1), port 5432 failed: Cannot assign requested address\n\tIs the server running on that host and accepting TCP/IP connections?\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dbapi_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_dbapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mraw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3297\u001b[0m         \"\"\"\n\u001b[0;32m-> 3298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \"\"\"\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ConnectionFairy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m_checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfairy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m             \u001b[0mfairy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36mcheckout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/impl.py\u001b[0m in \u001b[0;36m_do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dec_overflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/util/langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# remove potential circular references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/impl.py\u001b[0m in \u001b[0;36m_do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error on connect(): %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/util/langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# remove potential circular references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarttime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbapi_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Created new connection %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/create.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# inherits the docstring from interfaces.Dialect.connect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_dbapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]  # NOQA: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (::1), port 5432 failed: Cannot assign requested address\n\tIs the server running on that host and accepting TCP/IP connections?\n",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-eff101ae0fc4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'postgresql+psycopg2://dell:dell@localhost:5432/dell'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Cria uma conexão com o banco de dados utilizando o SQLAlchemy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"glicose\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Realiza a leitura dos dados da tabela para um Dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Encerra a conexão com o banco de dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mdtype_backend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSQLiteDatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             return pandas_sql.read_query(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, need_transaction)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSQLDatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_transaction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0madbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adbc_driver_manager.dbapi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, con, schema, need_transaction)\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m             \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_transaction\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3272\u001b[0m         \"\"\"\n\u001b[1;32m   3273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraw_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPoolProxiedConnection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dbapi_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_dbapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 Connection._handle_dbapi_exception_noconnection(\n\u001b[0m\u001b[1;32m    149\u001b[0m                     \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception_noconnection\u001b[0;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[1;32m   2437\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0msqlalchemy_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2439\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dbapi_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_dbapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 Connection._handle_dbapi_exception_noconnection(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mraw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m         \"\"\"\n\u001b[0;32m-> 3298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \"\"\"\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ConnectionFairy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_return_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConnectionPoolEntry\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m_checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     ) -> _ConnectionFairy:\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfairy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m             \u001b[0mfairy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mthreadconns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36mcheckout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConnectionRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/impl.py\u001b[0m in \u001b[0;36m_do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dec_overflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/util/langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# remove potential circular references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# remove potential circular references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/impl.py\u001b[0m in \u001b[0;36m_do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inc_overflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;34m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     def _invalidate(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error on connect(): %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/util/langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# remove potential circular references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# remove potential circular references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/pool/base.py\u001b[0m in \u001b[0;36m__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarttime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbapi_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Created new connection %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/create.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    644\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mcreator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"creator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDBAPIConnection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# inherits the docstring from interfaces.Dialect.connect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_dbapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]  # NOQA: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_connect_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mConnectArgsType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (::1), port 5432 failed: Cannot assign requested address\n\tIs the server running on that host and accepting TCP/IP connections?\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AP_kBL7oJzR6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
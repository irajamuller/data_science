{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ40Q293hIdpWM4+WAW6Ih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irajamuller/data_science/blob/main/Prepara%C3%A7%C3%A3o_de_Dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.NumPy**\n",
        "---\n",
        "<p align=\"justify\">\n",
        "O <code>ndarray</code> é a estrutura de dados básica da biblioteca Numpy. Qualquer um dos métodos analíticos implementados pelo NumPy irá requerer que os dados estejam armazenados nesta estrutura. Por se tratar de uma estrutura voltada para alto desempenho, o ndarray é implementado como um nódulo de baixo nível escrito na linguagem C utilizando a API para interface com a linguagem Python. Este método de implmeentação é comumente utilizado por módulos que requerem operações de alto desempenho, as quais não são suportadas pelos métodos ou estruturas nativas da linguagem Python.\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "Em baixo nível, o ndarray é uma estrutura de dados alocada de forma contígua em memória, armazenando elementos de forma compacta e homogênea em memória. Diferentemente das estruturas básicas do Python, um ndarray armazena valores de um único tip\\o de dados, o qual é definido no momento em que a estrutura é instanciada. Há suporte para a maioria dos tipos inteiros e de ponto flutuante que estão disponíveis em linguagens de programação com tipagem forte (tal como o C). A informação do tipo de dados encontra-se armazenada em uma estrutura de cabeçalho, a qual também irá conter outros metadados da estrutura, tal como duas dimensões e tamanhos. Estas informações são utilizadas para controlar operações de leitura e escrita de dados na estrutura de forma eficiente por cálculos de deslocamento. A figura abaixo apresenta um diagrama que sumariza a estrutura de baixo nível do ndarray.\n",
        "</p>\n",
        "\n",
        "<center>\n",
        "\n",
        "![Estrutura do ndarray](https://raw.githubusercontent.com/irajamuller/data_science/main/figs/ndarray_structure.jpg)\n",
        "\n",
        "</center>\n",
        "\n",
        "<p align=\"justify\">\n",
        "Por se tratar de uma estrutura simples e eficiente para manipulação de dados numéricos vetoriais, o ndarray é utilizado internamente por uma ampla gama de outras bibliotecas do Python que também tem o requisito de alto desempenho. Alguns exemplos incluem Pytorch e Tensorflow (duas bibliotecas amplamente utilizadas para trabalho com redes neurais profundas), OpenCV (biblioteca para trabalho com visão computacional), e a própria Pandas.\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "Neste notebook iremos aprender algumas das funções básicas disponíveis para a criação e manipulação de ndarrays. Antes de qualquer coisa, precisamos instalar a biblioteca NumPy em nosso ambiente Python e importar o NumPy para nosso notebook.\n",
        "</p>"
      ],
      "metadata": {
        "id": "3YSjVf-dlsl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip show numpy\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ttiEwFpdx3io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Com o a biblioteca NumPy importada, podemos utilizar os métodos disponíveis para a criação de ndarrays com diferentes características. Uma possibilidade é a criação de um ndarray com todos os valores inicializados com zero. Para isso, podemos utilizar o método <code>zeros</code>. O primeiro parâmetro para este método são as dimensões do ndarray, que no caso de duas dimensões será uma tupla <code>(linhas, colunas)</code>. Também utilizaremos o parâmetro <code>dtype</code> para especificar o tipo de dado que será armazenado, que no exemplo será um inteiro de 32 bits.\n",
        "</p>"
      ],
      "metadata": {
        "id": "8qYYEuqQyTON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndarray = np.zeros((3, 4), dtype=np.int32) # Cria um ndarray com dimensões 3 por 4\n",
        "print(ndarray)"
      ],
      "metadata": {
        "id": "GKpoNrsfybzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Neste caso, para alterar valores pontuais do ndarray, podemos utilizar indexação de arrays utilizando colchetes, como no exemplo abaixo. Repare que, assim como em outras linguagens de programação, a indexação de linhas e colunas inicia em $0$ e se estende até $n-1$ (onde $n$ é o limite da dimensão que está sendo acessada).\n",
        "</p>"
      ],
      "metadata": {
        "id": "FEWatg7gymjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndarray[1, 2] = 5 # Altera o valor do item na posição [2, 3] para 5\n",
        "print(ndarray)"
      ],
      "metadata": {
        "id": "V7D4SNm3ypQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Outro método comumente utilizado para criar um ndarray é a partir de uma outra estrutura do Python, tal como uma lista com valores inteiros. Também podemos utilizar o encadeamento para criar um ndarray utilizando as listas tradicionais do Python, como realizado no exemplo abaixo, através do método <code>array</code>. Repare que este método também permite especificar o tipo de dado que será utilizado pelo ndarray.\n",
        "</p>"
      ],
      "metadata": {
        "id": "brZ8gA3Bywdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista_python = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12] ]\n",
        "ndarray = np.array(lista_python, dtype=np.float32) # Cria um ndarray utilizando os dados contidos em uma lista do Python\n",
        "print(ndarray)"
      ],
      "metadata": {
        "id": "30wWa5TUy1XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Assim como no caso do Pandas, também podemos realizar a carga de dados para um ndarray a partir de um arquivo de texto no formato CSV. O exemplo abaixo utiliza o método <code>loadtxt</code> para ler um arquivo CSV, especificando o separador de cada coluna como uma vírgula. O método também permite especificar qual o tipo de dado que será utilizado para a conversão do array.\n",
        "\n",
        "Observe que o ndarray é uma estrutura menos flexível que o Dataframe do Pandas. Enquanto o Dataframe permite converter cada coluna para um tipo de dados distinto, no ndarray espera que todos os valores pertençam ao mesmo tipo de dados.\n",
        "</p>"
      ],
      "metadata": {
        "id": "SVRV32pwy8nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temps = np.loadtxt('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/temperaturas_outono.csv'\n",
        ", delimiter=',', dtype=np.float32) # Carrega os dados de um arquivo CSV para um ndarray\n",
        "print(temps)"
      ],
      "metadata": {
        "id": "bUCNukgnzBsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "A biblioteca NumPy também permite salvar e carregar os dados de um ndarray de um arquivo binário. Este formato usualmente é referido com a extensão NPY e se trata de um formato binário específico para armazenar informações de um ndarray do NumPy. Este formato é suportado pelo próprio NumPy e por algumas bibliotecas do Python, como o Pandas.\n",
        "</p>"
      ],
      "metadata": {
        "id": "G01IBut30Rng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('temperaturas.npy', temps) # Salvar os dados contidos no ndarray em um arquivo binário"
      ],
      "metadata": {
        "id": "xA1Y3Rae0XAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carregado = np.load('temperaturas.npy') # Carrega os dados contidos para um ndarray. O arquivo deve obedecer o formato binário esperado pelo NumPy\n",
        "print(carregado)"
      ],
      "metadata": {
        "id": "hUOGqiNX0ugU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "O NumPy oferece alguns comandos básicos para analisar as propriedades básicas de um ndarray, tais como o tamanho, dimensões, e tipo dos dados. As células abaixo contém exemplos do uso desses comandos utilizando o ndarray que carregamos no último exemplo.\n",
        "</p>"
      ],
      "metadata": {
        "id": "N9IBtx5h011J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado.size) # propriedade contendo o número de itens armazenados no ndarray"
      ],
      "metadata": {
        "id": "vYFTe-c804Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado.dtype) # propriedade contendo o tipo de dado armazenado em cada um dos itens do ndarray"
      ],
      "metadata": {
        "id": "mS22p5u105rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado.ndim) # propriedade contendo o número de dimensões contidas no ndarray"
      ],
      "metadata": {
        "id": "bWoe__tt09f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado.shape) # propriedade contendo uma tupla que especifica o tamanho de cada dimensão do ndarray"
      ],
      "metadata": {
        "id": "7KqLGEHw1AqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Um exemplo anterior já mostrou que podemos acessar elementos individuais de um ndarray utilizando o operador de indexação do Python (especificando a posição numérica entre colchetes). Podemos utilizar os operadores de indexação do Python para acessar diferentes porções do ndarray. As células abaixo apresentam algusn exemplos de operações de indexação.\n",
        "</p>"
      ],
      "metadata": {
        "id": "p7gk9F6m2A3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado[0]) # acessa uma linha completa do array utilizando através da indexação de uma dimensão"
      ],
      "metadata": {
        "id": "IotPX_NV2E28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado[0, :12]) # Acessa os 12 primeiros valores contidos na primeira linha"
      ],
      "metadata": {
        "id": "Au1ig_FN2IXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado[:, :12]) # Acessa os 12 primeiros valores contidos em cada uma das linhas"
      ],
      "metadata": {
        "id": "ijGAxOVn2K79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(carregado[:, 0]) # Cria um ndarray com o primeiro valor de cada uma das linhas"
      ],
      "metadata": {
        "id": "OXPkMZN72SYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Um ndarray também pode ser manipulado através de funções de divisão e agregação. Isso permite que, por exemplo, um ndarray seja dividido em um número especificado de partes iguais. As células abaixo apresentam exemplos dos métodos de divisão e concatenação.\n",
        "</p>"
      ],
      "metadata": {
        "id": "1rVWHJCN2ike"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "por_dia = np.split(carregado, 7) # divide o ndarray em sete partes iguais na dimensão de mais alto nível\n",
        "for dia in por_dia:\n",
        "    print(dia) # Imprime cada um das divisões criadas pelo comando split."
      ],
      "metadata": {
        "id": "KA8qWncq2mFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatenado = np.concatenate(por_dia)\n",
        "print(concatenado)"
      ],
      "metadata": {
        "id": "YXgTX9ng24uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Pandas**\n",
        "---\n",
        "<p align=\"justify\">\n",
        "O dataframe é a principal estrutura de dados disponibilizada pela biblioteca Pandas para o processamento e análise de dados. Todos os métodos disponíveis na bibloteca utilizam o Dataframe como estrutura básica para execução. O dataframe do pandas pode ser comparado com uma planilha de aplicativos como o Microsoft Excel, onde os dados são organizados de forma tabular. Cada linha da tabela representa um registro, identificado unicamente por um valor inteiro, e cada coluna representa um dos campos disponíveis no registro, identificada por uma string.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Cada coluna de um dataframe é representada como um objeto do tipo Series do Pandas. Em suma, uma Series é um array indexado por valores inteiros onde todos os elementos pertencem a um mesmo tipo. Cabe ressaltar que tanto o Dataframe quanto a Series são tipos de dados implementados de forma otimizada utilizanod extensões em linguagem de baixo nível de forma a apresentarem alto desempenho ao tratar grandes volumes de dados. A figura abaixo apresenta uma ilustração de como um Dataframe do Pandas é organizado.\n",
        "</p>\n",
        "<center>\n",
        "\n",
        "![Estrutura de um Dataframe do Pandas](https://raw.githubusercontent.com/irajamuller/data_science/main/figs/pandas_structure.jpg)\n",
        "\n",
        "</center>\n",
        "\n",
        "<p align=\"justify\">\n",
        "Para utilizarmos um Dataframe, primeiramente precisamos importar a biblioteca Pandas no nosso código.\n",
        "</p>"
      ],
      "metadata": {
        "id": "HDu_Nn243iyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n9f0i4Ey8uAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "No exemplo abaixo, iremos criar um novo Dataframe utilizando os dados contidos em um dicionário do Python. Repare na forma como o diconário está organizado e como ele será estruturado na forma de um Dataframe.\n",
        "</p>"
      ],
      "metadata": {
        "id": "M-3kGTTR8yPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Nome': ['Ana', 'João', 'Maria', 'Carlos', 'Paula'],\n",
        "    'Idade': [23, 34, 45, 36, 27],\n",
        "    'Cidade': ['SP', 'RJ', 'MG', 'RS', 'SP'],\n",
        "    'Glicose': [85, 140, 95, 200, 105]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df # Jupyter Notebook irá formatar o Dataframe como uma planilha."
      ],
      "metadata": {
        "id": "-vs-F0ma8x0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o Dataframe criado, podemos realizar diferentes atividades de seleção e manipulação dos dados nele contidos."
      ],
      "metadata": {
        "id": "T4IOkOvP9Get"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() # imprime uma série de informações sobre a estrutura do Dataframe."
      ],
      "metadata": {
        "id": "w0XwaU3L-r6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nomes = df['Idade'] # seleciona a Series contendo apenas os dados da coluna \"Idade\"\n",
        "nomes"
      ],
      "metadata": {
        "id": "J3AWmhab9Hbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registros = df[ df['Glicose'] > 100 ] # Selecionar registros aplicando um filtro nos valores de uma coluna\n",
        "registros # Jupyter Notebook irá formatar o Dataframe como uma planilha."
      ],
      "metadata": {
        "id": "HSnh0_g29c4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtro = (df['Glicose'] > 100) & (df['Idade'] < 35) # Vamos definir um filtro com várias condições\n",
        "registros = df[ filtro ] # Vamos selecionar os registros utilizando o filtro\n",
        "registros # Jupyter Notebook irá formatar o Dataframe como uma planilha."
      ],
      "metadata": {
        "id": "XAm43Co79ies"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registro = df.iloc[2] # seleciona um registro em particular (uma das linhas) do Dataframe\n",
        "registro"
      ],
      "metadata": {
        "id": "lhVRlzlU9wBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registro = registros.loc[4] # seleciona um registro em particular (uma das linhas) do Dataframe usando o label\n",
        "registro"
      ],
      "metadata": {
        "id": "wHBqePqM92hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = df.sample() # Seleciona um registro aleatório (uma amostra ou \"sample\") do Dataframe.\n",
        "sample # Jupyter Notebook irá formatar a amostra como uma planilha."
      ],
      "metadata": {
        "id": "xs7QEBjx-kB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_dataframe = df.sort_values('Idade') # Ordena os valores do Dataframe pela coluna passada como parâmetro.\n",
        "sorted_dataframe # Jupyter Notebook irá formatar a amostra como uma planilha."
      ],
      "metadata": {
        "id": "MTrerURd-1Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Para os próximos exemplos, precisaremos de um conjunto de dados com maior tamanho. Temos alguns conjuntos de dados de exemplo disponíveis na biblioteca Seaborn (biblioteca de visualização baseada na matplotlib), a qual também é ampalmente utilizada para tarefas de aprendizado de máquina e iremos estudar ao longo da disciplina. A célula abaixo irá carregar a biblioteca Seaborn e, em seguida, carregar um conjunto de dados com dados de gorjetas em restaurantes dos Estados Unidos.\n",
        "</p>"
      ],
      "metadata": {
        "id": "Bg6GwRnS_L7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "df = sns.load_dataset('tips')"
      ],
      "metadata": {
        "id": "fpKHnpjc_HcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As próximas células irão apresentar mais algumas funções básicas dos Dataframes."
      ],
      "metadata": {
        "id": "9RsxY-1j_uCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10) # Imprime os primeiros registros contidos no Dataframe."
      ],
      "metadata": {
        "collapsed": true,
        "id": "1EfjMhRd_ram"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(10) # Imprime os últimos registros contidos no Dataframe."
      ],
      "metadata": {
        "id": "TXX_CQKkAOou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe() # Apresenta uma análise das tendências centrais dos atributos numéricos contidos no Dataframe."
      ],
      "metadata": {
        "id": "9e5HfoMnASbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Também podemos realizar a seleção de subconjuntos de dados de um Dataframe através de operadores de indexação. As células abaixo apresentam exemplos onde selecionamos um subconjunto de registros com todas as colunas e, após, a seleção de um subconjunto de registros de uma coluna específica.\n",
        "</p>"
      ],
      "metadata": {
        "id": "zaKTFiEPAhZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[10:19]"
      ],
      "metadata": {
        "id": "kWalBweqAfiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[10:19, 'tip']"
      ],
      "metadata": {
        "id": "arsE677fAqQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 - Carregamento\n",
        "---\n",
        "<p align=\"justify\">\n",
        "Além de utilizar dicionários para criar Dataframes do Pandas, também podemos realizar a carga de dados diretamente de diferentes tipos de fontes de dados. O Pandas possui suporte nativo à leitura de vários formatos estruturados de arquivo, incluindo CSV e planilhas geradas por aplicativos como o Microsoft Excel. Utilizando as funcionalidades do Pandas podemos realizar tanto a leitura quanto a exportação de resultados diretamente para esses formatos.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Além disso, o Pandas também possui integração com a biblioteca SQLAlchemy do Python, que permite a interação com diferentes sistemas de gerenciamento de bancos de dados relacionais. Através desta integração podemos realizar a leitura de conjuntos de dados diretamente de tabelas de um banco de dados ou através de manipulações utilizando a linguagem SQL.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Este notebook apresenta os métodos que podemos utilizar para adquirir dados de fontes estruturadas no formato CSV (Dados de texto separados por vírgulas), XLSX (planilhas do Excel) e JSON (JavaScript Object Notation). Ele também apresenta como adquirir dados de bancos de dados relacionais utilizando a integração com o SQLAlchemy.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Nosso primeiro passo será carregar a biblioteca Pandas para utilizarmos o Dataframe e os métodos de carga de dados.\n",
        "</p>"
      ],
      "metadata": {
        "id": "xcLwu39pFQZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 - CSV\n",
        "---"
      ],
      "metadata": {
        "id": "T23n0miCHYj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/glicose.csv') # Realiza a leitura de um arquivo CSV\n",
        "#df = pd.read_csv('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/glicose.csv', delimiter=',') # Especifica que o caractere delimitador é uma vírgula\n",
        "df.info()"
      ],
      "metadata": {
        "id": "LTPHMWQQFn3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "O conjunto de dados que carregamos possui uma coluna \"Estado\" onde cada entrada é classificada pela UF do paciente. Repare que o comando <code>info</code> nos mostra que este atributo é do tipo <code>object</code>, o padrão para dados de string. Além de dados numéricos e de string, uma coluna também pode ser do tipo **categórico**. Este tipo de dado é muito útil para armazenar atributos que classificam uma entrada de acordo com um determinado conjunto limitado de categorias, tal como a UF de residência ou o tipo sanguíneo.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "A conversão de uma coluna para um tipo categórico precisa ser realizada de forma explícita através do método <code>astype</code>. Este método pode ser executado após o Dataset ter sido carregado de um arquivo.\n",
        "</p>"
      ],
      "metadata": {
        "id": "q3sSBbdDGJzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Estado'] = df['Estado'].astype(\"category\") # Converte a coluna \"Estado\" para um tipo categórico\n",
        "df.info()"
      ],
      "metadata": {
        "id": "yVttLSS0GSsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "zeAWhFqTGZ2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Também podemos salvar um conjunto de dados em um arquivo CSV através do método <code>to_csv</code>. As células abaixo apresentam um exemplo deste método. Primeiro, iremos criar um dataframe com um subconjunto de entradas do nosso dataset original. Então, iremos salvá-lo como um novo arquivo CSV.\n",
        "</p>"
      ],
      "metadata": {
        "id": "k3TaHbLYGiOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glicose_rs = df[ df[\"Estado\"] == \"RS\" ]\n",
        "glicose_rs"
      ],
      "metadata": {
        "id": "Y3zmu2iIGhvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glicose_rs.to_csv('glicose_rs.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DemFylXDGzf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 - XLSX\n",
        "---\n",
        "<p align=\"justify\">\n",
        "Podemos realizar a leitura de uma planilha do Excel através do método <code>read_excel</code>. Assim como no caso anterior, este comando presumo que a primeira linha da planilha irá conter os nomes dos atributos, os quais serão utilizados para nomear os respectivos atributos no Dataframe. O método também presume que a primeira planilha do arquivo deverá ser lida, mas podemos alterar este comportamento através dos parâmetros do comando.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Nota: para que o Pandas consiga ler arquivos do Excel, a biblioteca <code>openpyxl</code> precisa ser instalada no ambiente do Python.\n",
        "</p>"
      ],
      "metadata": {
        "id": "uCBsXZbIHpMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/glicose.xlsx') # Realiza a leitura de uma planilha do Excel.\n",
        "#df = pd.read_excel('glicose.xlsx', sheet_name='Sheet1') # Especifica o nome da planilha que deve ser lida do arquivo.\n",
        "df.info()"
      ],
      "metadata": {
        "id": "3hOB2UxgIAe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Também podemos exportar um Dataframe para um arquivo um arquivo de planilha utilizando o método <code>to_excel</code>. É interessante observar que este mesmo método também permite salvar arquivos ODS, que é formato aberto de planilha utilizado pelo LibreOffice. Para isso, utilizamos os parâmetros do método <code>to_excel</code> para especificar qual formato queremos utilizar.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "<strong>Nota</strong>: para habilitar o suporte ao formato ODS, também precisamos instalar a biblioteca <code>odfpy</code> através no ambiente do Python.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "No exemplo a seguir, iremos criar um dataframe com um subconjunto de dados e então iremos salvá-lo no formato ODS.\n",
        "</p>"
      ],
      "metadata": {
        "id": "9resG12iIQt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glicose_sp = df[ df[\"Estado\"] == \"SP\" ]\n",
        "glicose_sp"
      ],
      "metadata": {
        "id": "JKIPrXfvIXHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install odfpy --quiet # Instalação da Engine\n",
        "\n",
        "glicose_sp.to_excel('glicose_sp.ods', engine='odf', index=False)"
      ],
      "metadata": {
        "id": "P0jF421oIad8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3 - SGBDR\n",
        "---\n",
        "<p align=\"justify\">\n",
        "Outro método de aquisição de dados que é bastante popular é através de sistemas de bancos de dados relacionais. O Pandas possui integração com diferentes bibliotecas para acesso a bancos de dados, mas o SQLAlchemy é uma das mais flexíveis. Por si só, o SQLAlchemy possui um conjunto de ferramentas para trabalho com bancos de dados relacionais, como por exemplo um modelo para modelagem objeto-relacionamento.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Para utilizar estas funcionalidades com o Pandas, precisamos importar a biblioteca <code>sqlalchemy</code> no nosso código. Para uso das funcionalidades mais básicas, podemos importar apenas o método <code>create_engine</code>. A constar, precisamos instalar a biblioteca <code>sqlalchemy</code> no nosso ambiente Python para poder utilizá-la.\n",
        "</p>"
      ],
      "metadata": {
        "id": "eooQ3FSIJX5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlalchemy --quiet # Biblioteca de conexão Engine para o Python\n",
        "!wget https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/glicose.sqlite --quiet"
      ],
      "metadata": {
        "id": "0NDRMhsIKCcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Nos próximos exemplos, iremos utilizar um conjunto de dados armazenado em um arquivo de banco de dados relacional do SQLite. Este banco de dados possui uma única tabela denominada <code>tabela_glicose</code>, a qual possui a mesma estrutura do arquivo CSV que utilizamos em exemplos anteriores. Para importar a estrutura completa da tabela do banco de dados, podemos seguir o exemplo abaixo.\n",
        "</p>"
      ],
      "metadata": {
        "id": "t3OkchY5JocF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "# POSTGRESQL -> postgresql://dell_user:7CQirImbjo7U7yqGVWxlXWetCGU5gfqw@dpg-d0m8vegdl3ps73c5belg-a.oregon-postgres.render.com/dell\n",
        "engine = create_engine(\"sqlite:///glicose.sqlite\") # Cria uma conexão com o banco de dados utilizando o SQLAlchemy\n",
        "df = pd.read_sql(\"tabela_glicose\", engine) # Realiza a leitura dos dados da tabela para um Dataframe\n",
        "engine.dispose() # Encerra a conexão com o banco de dados\n",
        "df.head()"
      ],
      "metadata": {
        "id": "eZL5lciTIh8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Também podemos realizar consultas complexas através de comandos SQL ao realizar a importação de dados através do SQLAlchemy. O exemplo abaixo demonstra como utilizar essa funcionalidade realizando a importação de dados de pacientes que estão localizados apenas no estado do RS.\n",
        "</p>"
      ],
      "metadata": {
        "id": "LcpyjfByWNLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "engine = create_engine(\"sqlite:///glicose.sqlite\") # Cria uma conexão com o banco de dados utilizando o SQLAlchemy\n",
        "query = \"\"\"\n",
        "  SELECT *\n",
        "  FROM tabela_glicose\n",
        "  WHERE Estado = 'RS'\n",
        "\"\"\" # Especifica a consulta que será realizada no banco de dados\n",
        "glicose_rs = pd.read_sql_query(query, engine) # Realiza a leitura dos dados de acordo com a consulta realizada\n",
        "engine.dispose() # Encerra a conexão com o banco de dados\n",
        "\n",
        "glicose_rs.head()"
      ],
      "metadata": {
        "id": "AP_kBL7oJzR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.4 - JSON\n",
        "---\n",
        "<p align=\"justify\">\n",
        "A biblioteca pandas também permite ler um formatação de interoperabilidade de dados chamado JSON. Muitas aplicações utilizam esse formato, como, por exemplo, a especificação do sistema PIX.\n",
        "</p>"
      ],
      "metadata": {
        "id": "u-LjUzpdWxjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/glicose.json')\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "5pU-11hXXBQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uma forma bastante comum de usar objetos JSON é no \"achatamento\" (ou desconstrução $unwind no MongoDB) das chaves, pois existem objetos JSON aninhados \"cursos\"\n",
        "json_data = [\n",
        "    { \"nome\": \"Gilberto\", \"idade\": 50, \"peso\": 100, \"cursos\": [{\"nome\": \"Pandas for Dummies\"}, {\"nome\": \"NumPy for dummies\" }] },\n",
        "    { \"nome\": \"Gilberto\", \"idade\": 50, \"peso\": 100, \"cursos\": [{ \"nome\": \"Pandas for Dummies\" }, {\"nome\": \"NumPy for dummies\" }] }\n",
        "]\n",
        "\n",
        "df = pd.json_normalize(\n",
        "    json_data,\n",
        "    record_path='cursos',\n",
        "    meta=['nome', 'idade', 'peso'],\n",
        "    record_prefix='curso_'\n",
        ")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "IcOQCULOPWK1",
        "outputId": "ed4ec618-cc4f-45ca-e944-5c85ca19df15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           curso_nome      nome idade peso\n",
              "0  Pandas for Dummies  Gilberto    50  100\n",
              "1   NumPy for dummies  Gilberto    50  100\n",
              "2  Pandas for Dummies  Gilberto    50  100\n",
              "3   NumPy for dummies  Gilberto    50  100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c18db50d-5d66-4df3-ab89-d9b477d19416\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>curso_nome</th>\n",
              "      <th>nome</th>\n",
              "      <th>idade</th>\n",
              "      <th>peso</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pandas for Dummies</td>\n",
              "      <td>Gilberto</td>\n",
              "      <td>50</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NumPy for dummies</td>\n",
              "      <td>Gilberto</td>\n",
              "      <td>50</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pandas for Dummies</td>\n",
              "      <td>Gilberto</td>\n",
              "      <td>50</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NumPy for dummies</td>\n",
              "      <td>Gilberto</td>\n",
              "      <td>50</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c18db50d-5d66-4df3-ab89-d9b477d19416')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c18db50d-5d66-4df3-ab89-d9b477d19416 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c18db50d-5d66-4df3-ab89-d9b477d19416');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9d0756c7-5a4b-44da-9918-7c58ff5b8949\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d0756c7-5a4b-44da-9918-7c58ff5b8949')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9d0756c7-5a4b-44da-9918-7c58ff5b8949 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"curso_nome\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NumPy for dummies\",\n          \"Pandas for Dummies\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Gilberto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idade\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 50,\n        \"max\": 50,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"peso\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 100,\n        \"max\": 100,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}
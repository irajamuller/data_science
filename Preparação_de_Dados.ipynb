{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOaNr/c1PwfUHUN6SaLDBP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irajamuller/data_science/blob/main/Prepara%C3%A7%C3%A3o_de_Dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Tratamento Básico de Dados**\n",
        "---\n",
        "<p align=\"justify\">\n",
        "Este notebook apresenta os métodos mais fundamentais para o tratamento de conjuntos de dados utilizando o Dataframe da biblioteca Pandas. Iremos nos focar nos métodos para trabalhar com:\n",
        "</p>\n",
        "\n",
        "- Ajuste de colunas;\n",
        "- Análise e tratamento de dados faltantes;\n",
        "- Análise e tratamento de dados duplicados.\n",
        "\n",
        "<p align=\"justify\">\n",
        "Para esta atividade iremos utilizar uma versão modificada do conjunto de dados <strong>titanic</strong>. A versão original do conjunto de dados encontra-se disponível através da biblioteca Seaborn. Entretanto, neste exercício, iremos utilizar uma versão que apresenta dados modificados para ressaltar alguns problemas presentes em conjuntos de dados não tratados.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Neste notebook iremos utilizar apenas a biblioteca Pandas. Primeiramente, iremos carregar o conjunto de dados modificado, o qual encontra-se disponível no github <strong>titanic.csv</strong>.\n",
        "</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "3YSjVf-dlsl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/titanic.csv') # Carrega o conjunto de dados\n",
        "df.info() # Apresenta informações gerais sobre a estrutura do conjunto de dados"
      ],
      "metadata": {
        "id": "ttiEwFpdx3io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() # Exibe as primeiras entradas do conjunto de dados"
      ],
      "metadata": {
        "id": "9TxLaMnzh5St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "É importante compreender o contexto e o significado de cada um dos atributos do conjunto de dados para saber como utilizá-lo em tarefas de aprendizado de máquina. O <strong>titanic</strong> é um conjunto de dados aberto e bem documentado, permitindo facilmente encontrar informações sobre o significado e características de cada um dos atributos.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Vamos olhar primeiramente para os nomes das colunas. Algumas colunas apresentam nomes abreviados. Por exemplo, \"sibsp\" é um valor inteiro que indica quantos irmãos (siblings) ou cônjuges (spouses) estavam à bordo junto com o passageiro. Da mesma forma \"parch\" é um valor inteiro que indica quantos pais (parents) ou filhos (children) estavam à bordo junto com o passageiro. Para facilitar nossa interpretação do conjunto de dados, podemos renomear estas colunas. O código abaixo apresenta este processo.\n",
        "</p>\n",
        "<div align=\"center\">\n",
        "\n",
        "| **Coluna**    | **Descrição**                                                 |\n",
        "| ------------- | ------------------------------------------------------------- |\n",
        "| `survived`    | Sobreviveu (1 = sim, 0 = não)                                 |\n",
        "| `pclass`      | Classe do bilhete (1ª, 2ª, 3ª)                                |\n",
        "| `sex`         | Sexo do passageiro (`male` ou `female`)                       |\n",
        "| `age`         | Idade do passageiro                                           |\n",
        "| `sibsp`       | Nº de irmãos/cônjuges a bordo                                 |\n",
        "| `parch`       | Nº de pais/filhos a bordo                                     |\n",
        "| `fare`        | Valor pago na passagem (em libras)                            |\n",
        "| `embarked`    | Porto de embarque (`C`, `Q`, `S`)                             |\n",
        "| `class`       | Classe do bilhete (`First`, `Second`, `Third`)                |\n",
        "| `who`         | Tipo de pessoa (`man`, `woman`, `child`)                      |\n",
        "| `adult_male`  | Se é um homem adulto (`True` ou `False`)                      |\n",
        "| `deck`        | Letra do deck da cabine (`A` a `G`, ou ausente)               |\n",
        "| `embark_town` | Cidade de embarque (`Cherbourg`, `Queenstown`, `Southampton`) |\n",
        "| `alive`       | Está vivo (`yes`) ou não (`no`)                               |\n",
        "| `alone`       | Estava sozinho a bordo (`True` ou `False`)                    |\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "8qYYEuqQyTON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear colunas\n",
        "df = df.rename(columns={\n",
        "    \"sibsp\": \"siblings_spouses\",\n",
        "    \"parch\": \"parent_children\",\n",
        "    \"sex\": \"gender\"\n",
        "})\n",
        "\n",
        "df.info() # Exibe os metadados do conjunto de dados"
      ],
      "metadata": {
        "id": "GKpoNrsfybzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Valores Ausentes**\n",
        "<p align=\"justify\">\n",
        "Nosso próximo passo é avaliar os valores ausentes no conjunto de dados. Valores ausentes se referem a entradas no conjunto de dados que não possuem um valor registrado em um ou mais de seus atributos. Ao exibir o conjunto de dados, o Pandas mostra estas entradas através de um <strong>NaN</strong>, que é a abreviação para <strong>Not a Number</strong>. De modo geral, existem dois motivos porque registros podem apresentar atributos com valor ausente:\n",
        "</p>\n",
        "\n",
        "- A ausência do valor está correta pelo fato de que o valor de fato não existe;\n",
        "- Houve um problema na coleta de dados que impediu a aquisição do valor para uma parcela dos registros.\n",
        "\n",
        "<p align=\"justify\">\n",
        "Um exemplo do primeiro caso seria a existência de uma coluna para nome do cônjuge, a qual deveria permanecer vazia para passageiros solteiros. Neste caso, faz sentido não haver um valor registrado neste item e ele deve ser considerado pelo processo de aprendizado. Por sua vez, o segundo caso pode ocorrer por motivos como um processo de coleta falho ou erros de leitura em dispositivos. Nestes casos, deveria haver um valor nesta coluna, mas os motivos acima impediram que ele fosse registrado.\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "Existem diferentes métodos que podemos utilizar para tratar valores ausentes. O método a ser utilizado vai depender de diferentes fatores como a porcentagem de valores ausentes e a significância do parâmetro para o processo de aprendizado.\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "A célula abaixo demonstra como podemos avaliar o número de registros com valores ausentes para cada um dos atributos do conjunto de dados.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "FEWatg7gymjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Apresenta, para cada coluna, o total de registros que possui valores vazios.\n",
        "Também podem ser visualizado através do método \"info\".\n",
        "'''\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "V7D4SNm3ypQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "O método mais simples de tratamento é a remoção de qualquer registro que possua algum atributo com valor ausente no conjunto de dados. A célula abaixo apresenta o código para realizar este tipo de tratamento.\n",
        "</p>"
      ],
      "metadata": {
        "id": "brZ8gA3Bywdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped = df.dropna() # Realiza a remoção de qualquer registro no dataframe que possua algum valor vazio.\n",
        "df_dropped.info() # O resultado abaixo mostra que a remoção das colunas resultou na eliminação de 79,6% do Conjunto de dados."
      ],
      "metadata": {
        "id": "30wWa5TUy1XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Como podemos ver, a simples remoção de todos os registros com algum valor ausente causou a eliminação de aproximadamente 80% do conjunto de dados, o que pode inviabilizar a utilização do conjunto de dados. Uma alternativa mais interessante pode ser remover atributos que apresentam maior ausência de dados e não são relevantes para o processo de aprendizado. Os metadados do conjunto mostram que o atributo <strong>deck</strong> apresenta a maior parte dos valores ausentes. Portanto, iremos eliminá-lo de nosso conjunto de dados antes de remover os valores ausentes.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "SVRV32pwy8nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove uma coluna do conjunto de dados.\n",
        "df_dropped = df.drop(columns=['deck'])\n",
        "# Repetimos a operação de limpeza dos demais registros que possuem valores em branco.\n",
        "df_dropped = df_dropped.dropna()\n",
        "\n",
        "'''\n",
        "A remoção da coluna \"deck\" evita que uma porção considerável do conjunto de dados seja descartada\n",
        "Como resultado, o conjunto de dados limpo perdeu apenas 20,1% em comparação ao original.\n",
        "'''\n",
        "df_dropped.info()\n"
      ],
      "metadata": {
        "id": "bUCNukgnzBsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Dependendo do conjunto de dados e suas características, também podemos preencher os valores faltantes com dados sintéticos, tais como valores gerados a partir de cálculos estatísticos. Este tipo de tratamento requer uma análise cuidadosa dos valores gerados e suas implicações para o restante dos dados, pois ela pode causar viéses indesejados no processo de aprendizado.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Analisando nosso conjunto de dados, podemos ver que a coluna <strong>age</strong>, que registra a idade do passageiro, possui o segundo maior número de valores ausentes. Uma possível solução para eliminar os valores faltantes nesta coluna sem perder os registros através de eliminação seria preencher a idade dos passageiros com valores gerados a partir da análise do restante dos dados no conjunto.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "No exemplo abaixo iremos realizar um preenchimento simples utilizando o valor da mediana da idade dos passageiros.\n",
        "</p>"
      ],
      "metadata": {
        "id": "iFqsUaqdnE86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped = df.drop(columns=['deck']) # Remove uma coluna do conjunto de dados.\n",
        "'''\n",
        "Ao invés de remover os registros com valores faltantes, podemos substituílos por um valor padrão, por exemplo zero.\n",
        "No exemplo abaixo substituímos os valores faltantes apenas da coluna \"age\" por zero.\n",
        "'''\n",
        "median_age = df_dropped['age'].median()\n",
        "df_dropped['age'] = df_dropped['age'].fillna(median_age)\n",
        "\n",
        "df_dropped = df_dropped.dropna() # Repetimos a operação de limpeza dos demais registros que possuem valores em branco.\n",
        "df_dropped.info() # O resultado agora mostra que praticamente todo o dataset possui valores completos em seus registros.\n"
      ],
      "metadata": {
        "id": "xA1Y3Rae0XAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Além de valores faltantes, outra questão que requer atenção é a existência de <strong>registros duplicados</strong> no conjunto de dados. Dependendo do contexto do conjunto de dados e sua finalidade, registros duplicados podem causar inconsistências como o desbalanceamento de classes, o que poderia resultar e viéses indesejaveis em modelos de aprendizado. Por esse motivo, o Pandas oferece métodos que permitem identificar e eliminar registros duplicados.\n",
        "\n",
        "As células abaixo apresentam os métodos para identificar o número de registros duplicados e, após, realizar a sua eliminação do conjunto de dados.\n",
        "</p>"
      ],
      "metadata": {
        "id": "2arLaBsooCig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar itens duplicados (em todo o dataset)\n",
        "df_duplicated = df[df.duplicated()]\n",
        "df_duplicated.info()"
      ],
      "metadata": {
        "id": "h3ABPf6BphLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar itens duplicados\n",
        "# Cria uma lista que indica para cada registro do dataset se ele é uma duplicata ou não através de um valor booleano.\n",
        "df_duplicated = df_dropped.duplicated()\n",
        "print( f\"Registros duplicados: {df_duplicated.sum()}\" )\n"
      ],
      "metadata": {
        "id": "hUOGqiNX0ugU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realiza a limpeza de todas as duplicatas encontradas.\n",
        "df_dropped = df_dropped.drop_duplicates()"
      ],
      "metadata": {
        "id": "xMXWoXb0qSR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Padronização de Dados\n",
        "<p align=\"justify\">\n",
        "A padronização de dados diz respeito a diferentes tarefas de conversão que têm por objetivo tornar os dados tratáveis por métodos de aprendizado de máquina. É comum que conjuntos de dados reais apresentem inconsistências de preenchimento em dados categóricos ou de data, sendo necessário realizar tratamentos para que eles sejam interpretados de forma correta. Além disso, algoritmos de aprendizado de máquina apresentam melhor acurácia quando dados numéricos são normalizados para valores dentro de uma escala padronizada. Devemos analisar o nosso conjunto de dados e escolher os métodos que devem ser aplicados dependendo de quais algoritmos de aprendizado serão utilizados posteriormente.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Iremos trabalhar com métodos da biblioteca Pandas para a realização das seguintes atividades:\n",
        "</p>\n",
        "\n",
        "- Conversão de dados categóricos;\n",
        "- Tratamento de formatos de data;\n",
        "- Normalização de valores numéricos.\n",
        "\n",
        "<p align=\"justify\">\n",
        "Nesta atividade iremos utilizar um conjunto de dados <strong>fictício</strong> que apresenta informações sobre salários e tempo de serviço de pessoas em uma empresa. Este conjunto de dados encontra-se disponível no arquivo <strong>people.csv</strong>. Primeiramente iremos carregar a biblioteca Pandas, a qual iremos utilizar no restante da atividade, além de realizar a carga do conjunto de dados. Também iremos tratar os dados ausentes na coluna <strong>salario_bruto</strong> utilizando a mediana dos demais valores deste atributo.\n",
        "</p>"
      ],
      "metadata": {
        "id": "U9lIlEe6ANE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/people.csv') # Carregar o conjunto de dados\n",
        "df\n"
      ],
      "metadata": {
        "id": "nJGsB0UPAuzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mediana_salario = df[\"salario_bruto\"].median() # Tratar os dados ausentes na coluna de salários com a mediana dos valores presentes\n",
        "df[\"salario_bruto\"] = df[\"salario_bruto\"].fillna(mediana_salario).astype(float)"
      ],
      "metadata": {
        "id": "IbdYmh11Bb1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Fm1Ci2OlBUmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Primeiramente iremos padronizar o formato de colunas com dados de string. Em vários casos, dados de string são utilizados para categorização dos demais atributos. Apenas lembrando, atributos categóricos permitem classificar os dados entre diferentes categorias predefinidas. No conjunto de dados que estamos trabalhando, um exemplo é o atributo <strong>estado</strong>, que indica o estado de origem do empregado. Observando os dados contidos na coluna, podemos ver que há tanto versões onde o estado está em maiúsculas e, em outros casos, em minúsculas. Estas diferenças de formatação podem causar inconsistências quando tentamos converter essa coluna para um tipo categórico, resultando em mais de uma categoria criada para um mesmo estado, por exemplo.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Neste caso, precisamos tratar estes atributos para padronizar o seu formato. Como exemplo, iremos converter a coluna <strong>estado</strong> para um formato de caixa alta (todos caracteres maiúsculos) e a coluna <strong>cargo</strong> para um formato de caixa baixa (todos caracteres minúsculos).\n",
        "</p>"
      ],
      "metadata": {
        "id": "_h2yDD54B6WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"estado\"] = df[\"estado\"].str.upper() # Padronizar strings de estado para uppercase\n",
        "df[\"cargo\"] = df[\"cargo\"].str.lower().str.strip() # Padronizar cargos para lowercase e remover espaços extras\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "EFMP_57GCS2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Após a padronização destas informações, podemos transformar a coluna estado em um atributo categórico, conforme apresentado na célula abaixo.\n",
        "</p>"
      ],
      "metadata": {
        "id": "YpaT4MO_C6wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"estado\"] = df[\"estado\"].astype(\"category\") # Converter estado para categoria\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "BsiDpcszC5C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Em seguida, iremos tratar os dados de data que estão presentes nas colunas <strong>data_nascimento</strong> e <strong>ultima_avaliacao</strong>. Por padrão, o Pandas armazena a informação de datas como strings, sendo necessário converter estes atributos para informações de data e hora de forma explícita. Partindo do princípio que as colunas contenham formatos padrão para o armzenamento de informações de data e hora, a conversão pode ser realizada através do método <strong>to_datetime</strong>, conforme apresentado a seguir.\n",
        "</p>"
      ],
      "metadata": {
        "id": "s_Toj6IjDvXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrigir tipos de dados\n",
        "df[\"data_nascimento\"] = pd.to_datetime(df[\"data_nascimento\"])\n",
        "df[\"ultima_avaliacao\"] = pd.to_datetime(df[\"ultima_avaliacao\"])\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "1PkExhzWDsbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Podemos realizar processamentos adicionais com informações de data e hora. Por exemplo, podemos criar atributos adicionais com elementos individuais como o ano e o mês. Desta forma, o algoritmo de aprendizado pode tratar essas informações de forma individual caso isso seja necessário para a análise a ser realizada. A célula abaixo apresenta como é possível criar dois novos atributos a partir da informação contida na coluna <strong>ultima_avaliacao</strong>, a qual já foi previamente convertida para uma coluna com dados temporais.\n",
        "</p>"
      ],
      "metadata": {
        "id": "roI4tbAUEHEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar colunas derivadas a partir de datas\n",
        "df[\"ano_ultima_avaliacao\"] = df[\"ultima_avaliacao\"].dt.year\n",
        "df[\"mes_ultima_avaliacao\"] = df[\"ultima_avaliacao\"].dt.month\n",
        "\n"
      ],
      "metadata": {
        "id": "Kebp7BHbEQ3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Uma tarefa comum no tratamento de conjuntos de dados é a aplicação de técnicas para a normalização de valores de atributos. O objetivo da normalização é padronizar os valores de um atributo para uma escala controlada. O processo de normalização é comumente utilizado para escalar os valores de atributos para uma faixa aceita pelos algoritmos de aprendizado de máquina que serão aplicados. De forma geral, algoritmos de aprendizado apresentam melhores resultados quando não há uma disparidade muito grande entre as escalas de valores utilizadas pelos diferentes atributos numéricos. Além disso, algoritmos que trabalham com o conceito de distância, tal como clusterização, requerem que os atributos encontrem-se em faixas determinadas, por exemplo entre valores 0 e 1.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Existem diferentes métodos que podem ser aplicados para normalizar os valores de atributos. Neste notebook iremos trabalhar com o método de normalização min-max, que pode ser diretamente implementado através dos métodos disponíveis na biblioteca Pandas. Mais adiante também iremos trabalhar com outros métodos de normalização que podem ser implementados utilizando outras bibliotecas do Python como o SciPy.\n",
        "</p>\n",
        "<p align=\"justify\">\n",
        "Abaixo temos a fórmula utilizada para a normalização de valores utilizando min-max.\n",
        "</p>\n",
        "$X' = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}$\n",
        "\n",
        "- $X$ é o valor original que queremos normalizar\n",
        "- $X_{\\text{min}}$ é o valor mínimo presente no atributo que será normalizado\n",
        "- $X_{\\text{max}}$ é o valor máximo presente no atributo que será normalizado\n",
        "- $X'$ é o valor obtido a partir do processo de normalização\n",
        "\n",
        "<p align=\"justify\">\n",
        "A célula abaixo apresenta a aplicação deste método para dois atributos numéricos presentes no conjunto de dados.\n",
        "</p>"
      ],
      "metadata": {
        "id": "GmnQ93RkEd8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar salário utilizando escalonamento Min-Max\n",
        "df[\"salario_normalizado\"] = (df[\"salario_bruto\"] - df[\"salario_bruto\"].min()) / (df[\"salario_bruto\"].max() - df[\"salario_bruto\"].min())\n",
        "\n",
        "# Normalizar tempo de empresa utilizando escalonamento Min-Max\n",
        "df[\"tempo_empresa_anos\"] = (df[\"tempo_empresa_anos\"] - df[\"tempo_empresa_anos\"].min()) / (df[\"tempo_empresa_anos\"].max() - df[\"tempo_empresa_anos\"].min())\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ahPuhkPzEvAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Agregação de Dados\n",
        "<p align=\"justify\">\n",
        "Métodos de agregação de dados permitem sintetizar grandes volumes de informação e reduzir a complexidade computacional em seu gerenciamento. Métodos de agregação usualmente buscam a análise das tendências centrais de conjuntos de dados agrupados de acordo com categorias ou intervalos temporais. Estas técnicas são úteis para casos como conjuntos de dados que trabalham com dados temporais de alta granularidade, os quais usualmente apresentam um grande volume de dados que pode reduzir a eficiência de métodos de aprendizado de máquina complexos. Nestes casos, o uso da agregação permite reduzir a dimensionalidade do conjunto de dados sem comprometer a sua acurácia.\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "Métodos de agregação usualmente envolvem cálculos estatísticos de tendência central, como análise de médias, medianas e desvio padrão. Estes métodos estão disponíveis nativamente na biblioteca Pandas, mas também podem ser cálculados utilizando outras ferramentas do Python, como veremos mais adiante.\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "Este notebook apresenta alguns exemplos da aplicação de métodos de agregação utilizando o conjunto de dados disponível no arquivo <strong>people.csv</strong>, o qual já utilizamos neste módulo. Primeiramente iremos carregar a biblioteca Pandas e o respectivo conjunto de dados. Também iremos fazer uso de um método para padronizar a informação contida na coluna <strong>estado</strong> para caixa alta.</p>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "0ZX3XOO-Y1mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/irajamuller/data_science/main/dataset/people.csv') # Carrega o conjunto de dados\n",
        "\n",
        "df[\"estado\"] = df[\"estado\"].str.upper().astype(\"category\") # Padroniza os valores da coluna \"estado\" para caixa alta.\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "GP1M5R9NZNlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "A célula abaixo apresenta uma agregação simples onde os dados do atributo <strong>salario_bruto</strong> são agregados em função das categorias presentes no atributo <strong>estado</strong>. Para cada categoria, os valores de <strong>salario_bruto</strong> são agregado utilizando a média aritmética simples através do método <strong>mean</strong>.\n",
        "</p>"
      ],
      "metadata": {
        "id": "d9mV1JuNZp80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Média de salário por ano\n",
        "df.groupby(\"estado\", observed=True)[\"salario_bruto\"].mean()"
      ],
      "metadata": {
        "id": "j9k9yNU_Z4N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "O exemplo abaixo adiciona o ordenamento decrescente à exibição dos valores agregados por estado.\n",
        "</p>"
      ],
      "metadata": {
        "id": "0ZD-8eAIa-Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar estados pela média de salário, em ordem decrescente\n",
        "df.groupby(\"estado\", observed=True)[\"salario_bruto\"].mean().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "BLDL-9UrbDsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Um outro exemplo básico de agregação é a contagem de elementos presentes em uma categoria. A célula abaixo apresenta uma agregação onde cada registro contém o número de funcionários categorizado pelo atributo `estado`.\n",
        "</p>"
      ],
      "metadata": {
        "id": "eY-NVNSebb7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar o número de funcionários por estado\n",
        "df.groupby(\"estado\", observed=True)[\"id\"].count()"
      ],
      "metadata": {
        "id": "foiLS7qVba7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "No próximo exemplo iremos utilizar o atributo <strong>estado</strong> para agregar os valores de salário, similar ao primeiro exemplo. Porém, dessa vez iremos aplicar o método <strong>agg</strong>, que permite o cálculo de múltiplas métricas de tendência central de forma simultânea. A célula abaixo apresenta um exemplo com o número de entradas e valores de salário mínimo, máximo, médio e mediano.\n",
        "</p>"
      ],
      "metadata": {
        "id": "nHIrpXDib7EO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obter o salário mínimo, máximo e médio por cargo\n",
        "df.groupby(\"estado\", observed=True)[\"salario_bruto\"].agg([\"count\", \"min\", \"max\", \"mean\", \"median\"])"
      ],
      "metadata": {
        "id": "01j5UtFQcJW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "O método <strong>agg</strong> também permite o uso de funções personalizadas para a o cálculo de agregações além daquelas nativamente oferecidas. No exemplo abaixo, definimos uma função <strong>range_func</strong> que calcula a faixa entre os salários mínimos e máximos para cada item da agregação. Em seguida, a utilizamos no método <strong>agg</strong> para obter a faixa salarial para cada uma das categorias por estado.\n",
        "</p>"
      ],
      "metadata": {
        "id": "QGlYf6MOcSEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir uma função personalizada\n",
        "def my_min_max(x):\n",
        "    return x.max() - x.min()\n",
        "\n",
        "# Aplicar a função personalizada\n",
        "df.groupby(\"estado\", observed=True)[\"salario_bruto\"].agg([\"mean\", \"median\", my_min_max])"
      ],
      "metadata": {
        "id": "jjuWhMKacj51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "O método <strong>groupby</strong> também permite a agregação por múltiplos atributos. No exemplo abaixo, realiza-se a agregação do valor de salários de acordo com o estado e o cargo dos funcionários.\n",
        "</p>"
      ],
      "metadata": {
        "id": "9U0b1HIofCnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar por estado e cargo e calcular a média do salário\n",
        "df.groupby([\"estado\", \"cargo\"], observed=True)[\"salario_bruto\"].mean()"
      ],
      "metadata": {
        "id": "cXaqpkaWfKIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "A agregação também pode ser utilizada para a criação de novos atributos no conjunto de dados, acrescentando informações a cada um dos registros disponíveis. No exemplo abaixo, será adicionada o atributo <strong>media_salario_estado</strong>, contendo o valor médio do salário agregado pelo estado ao qual o funcionário pertence. Observe que o valor é adicionado para todos os registros do conjunto de dados de acordo com o valor da coluna <strong>estado</strong>.\n",
        "</p>"
      ],
      "metadata": {
        "id": "qinHDXJAfPdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar uma coluna com a média do salário por estado\n",
        "df[\"media_salario_estado\"] = df.groupby(\"estado\", observed=True)[\"salario_bruto\"].transform(\"mean\")\n",
        "df"
      ],
      "metadata": {
        "id": "dKDhI5wQfY0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "A combinação dos métodos <strong>groupby</strong> e <strong>agg</strong> também pode ser utilizada para o cálculo de valores agregados em múltiplos atributos. No exemplo abaixo, o atributo <strong>estado</strong> é utilizado para o agrupamento de valores de ambos atributos <strong>salario_bruto</strong> e <strong>tempo_empresa_anos</strong>. Observe que, para cada atributo, diferentes valores agregados serão calculados.\n",
        "</p>"
      ],
      "metadata": {
        "id": "JUnh6-hmgxA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"estado\", observed=True).agg({\n",
        "    \"salario_bruto\": [\"mean\", \"sum\"],\n",
        "    \"tempo_empresa_anos\": [\"max\", \"min\"]\n",
        "})"
      ],
      "metadata": {
        "id": "hLECA6v5g_kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Métodos de agrupamento também podem ser aplicados a atributos numéricos, em particular para a definição de faixas de valores. A célula abaixo apresenta um exemplo onde os valores de salário são agrupados de acordo com a faixa etária dos empregados. Para isso, definem-se três faixas etárias com diferentes escalas de idades. Em seguida, as faixas etárias são utilizadas para calcular a média salarial para os registros presentes em cada faixa etária.\n",
        "</p>"
      ],
      "metadata": {
        "id": "110_9YUbhOZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar por faixas etárias\n",
        "df[\"faixa_etaria\"] = pd.cut(df[\"idade\"], bins=[18, 30, 50, 80], labels=[\"Jovem\", \"Adulto\", \"Idoso\"])\n",
        "df.groupby(\"faixa_etaria\", observed=True)[\"salario_bruto\"].mean()\n"
      ],
      "metadata": {
        "id": "PnwEKCGthUrf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}